replicaCount: 1

ordinals:

  enabled: false
  start: 0

image:

  repository: atlassian/confluence
  pullPolicy: IfNotPresent
  tag: ""

serviceAccount:

  create: true
  name:
  imagePullSecrets: []
  annotations: {}

  role:
    create: true
  clusterRole:
    create: false
    name:
  roleBinding:
    create: true
  clusterRoleBinding:
    create: false
    name:
  eksIrsa:
    roleArn:

database:

  type: postgresql
  url: 'jdbc:postgresql://pgatlaciandb-ha.confluence.svc.cluster.local:5432/confluence_db'
  credentials:

    # 'kubectl create secret generic <secret-name> --from-literal=username=<username> --from-literal=password=<password>'
    secretName: confluence-db
    usernameSecretKey: username
    passwordSecretKey: password

volumes:
  localHome:
    persistentVolumeClaim:
      create: true
      storageClassName: local-path
      resources:
        requests:
          storage: 1Gi

    persistentVolumeClaimRetentionPolicy:
      whenDeleted:
      whenScaled:

    customVolume: {}
    # persistentVolumeClaim:
    #   claimName: "<pvc>"

    mountPath: "/var/atlassian/application-data/confluence"

  sharedHome:
    persistentVolumeClaim:
      create: true
      storageClassName: local-path
      resources:
        requests:
          storage: 1Gi

    customVolume: {}
    # persistentVolumeClaim:
    #   claimName: "<pvc>"

    mountPath: "/var/atlassian/application-data/shared-home"
    subPath:

    # Modify permissions on shared-home
    nfsPermissionFixer:
      enabled: true
      mountPath: "/shared-home"
      imageRepo: alpine
      imageTag: latest
      command:

  synchronyHome:

    persistentVolumeClaim:
      create: true
      storageClassName: local-path
      resources:
        requests:
          storage: 1Gi

    persistentVolumeClaimRetentionPolicy:

      whenDeleted:
      whenScaled:

    customVolume: { }
    # persistentVolumeClaim:
    #   claimName: "<pvc>"

    mountPath: "/var/atlassian/application-data/confluence"

  additional: []
  additionalSynchrony: []
  defaultPermissionsMode: 484


ingress:

  create: false
  openShiftRoute: false
  routeHttpHeaders: {}
  className: "nginx"
  nginx: true
  maxBodySize: 250m
  proxyConnectTimeout: 60
  proxyReadTimeout: 60
  proxySendTimeout: 60

  host:

  path:

  annotations: {}

  https: true

  tlsSecretName:

# Confluence configuration
confluence:

  # -- Whether the main container should acquire helm release name. By default the container name is `confluence` which corresponds to the name of the Helm Chart.
  #
  useHelmReleaseNameAsContainerName: false

  # K8s Confluence Service configuration
  #
  service:
    port: 80
    type: ClusterIP
    sessionAffinity: None
    sessionAffinityConfig:
      clientIP:
        timeoutSeconds:
    loadBalancerIP:

    contextPath:
    annotations: {}

  hazelcastService:
    enabled: false
    port: 5701
    type: ClusterIP
    annotations: {}

  securityContextEnabled: true
  securityContext:

    fsGroup: 2002
  containerSecurityContext: {}

  umask: "0022"

  setPermissions: true

  ports:
    http: 8090
    hazelcast: 5701

  # Confluence licensing details
  #
  license:

    # 'kubectl create secret generic <secret-name> --from-literal=license-key=<license>
    secretName:

    # -- The key in the K8s Secret that contains the Confluence license key
    secretKey: license-key

  readinessProbe:
    enabled: true
    initialDelaySeconds: 10
    periodSeconds: 5
    timeoutSeconds: 1
    failureThreshold: 6
    customProbe: {}

  startupProbe:

    # -- Whether to apply the startupProbe check to pod.
    #
    enabled: false

    # -- Time to wait before starting the first probe
    #
    initialDelaySeconds: 60

    # -- How often (in seconds) the Confluence container startup probe will run
    #
    periodSeconds: 5

    failureThreshold: 120

  livenessProbe:
    enabled: false
    initialDelaySeconds: 60
    periodSeconds: 5
    timeoutSeconds: 1
    failureThreshold: 12
    customProbe: {}

  # Confluence log configuration
  accessLog:
    enabled: true
    mountPath: "/opt/atlassian/confluence/logs"
    localHomeSubPath: "logs"

  # Data Center clustering
  #
  clustering:
    enabled: true
    usePodNameAsClusterNodeName: true

  # Use AWS S3 to store attachments. From Confluence 8.1 onwards.
  #

  s3AttachmentsStorage:

    bucketName:
    bucketRegion:
    endpointOverride:

  # Confluence Pod resource requests
  #
  resources:

    jvm:
      maxHeap: "1g"
      minHeap: "1g"
      reservedCodeCache: "256m"
    container:

      requests:
        cpu: "250m"
        memory: "1G"

  shutdown:

    terminationGracePeriodSeconds: 25
    command: "/shutdown-wait.sh"

  postStart:
    command:

  forceConfigUpdate: false
  additionalJvmArgs: []
  tomcatConfig:

    generateByHelm: false

    mgmtPort: "8000"
    port: "8090"
    maxThreads: "100"
    minSpareThreads: "10"
    connectionTimeout: "20000"
    enableLookups: "false"
    protocol: "org.apache.coyote.http11.Http11NioProtocol"
    redirectPort: "8443"
    acceptCount: "10"
    debug: "0"
    uriEncoding: "UTF-8"
    # secure is retrieved from ingress.https value
    secure:
    # scheme is set depending on ingress.https value (http if false, https if true)
    scheme:
    # proxyName is retrieved from ingress.host value
    proxyName:
    # proxyPort is set depending on ingress.https value (80 if http, 443 if https)
    proxyPort:
    maxHttpHeaderSize: "8192"
    proxyInternalIps:
    trustedProxies:

    # -- Custom server.xml to be mounted into /opt/atlassian/confluence/conf
    #
    customServerXml: |
  seraphConfig:
    generateByHelm: false

    autoLoginCookieAge: "1209600"
  additionalLibraries: []
  additionalBundledPlugins: []
  additionalVolumeMounts: []
  additionalEnvironmentVariables: []
  additionalPorts: []
  additionalVolumeClaimTemplates: []
  topologySpreadConstraints: []
  jvmDebug:
    enabled: false
  additionalCertificates:
    secretName:
    customCmd:

# Monitoring
#
monitoring:

  exposeJmxMetrics: false
  jmxExporterInitContainer:
    runAsRoot: true
    customSecurityContext: {}
    resources: {}
  jmxServiceAnnotations: {}
  fetchJmxExporterJar: true
  jmxExporterImageRepo: bitnami/jmx-exporter
  jmxExporterImageTag: 0.18.0
  jmxExporterPort: 9999

  # -- JMX exporter port type
  #
  jmxExporterPortType: ClusterIP

  # -- Location of jmx_exporter jar file if mounted from a secret or manually copied to shared home
  #
  jmxExporterCustomJarLocation:

  # -- Custom JMX config with the rules
  #
  jmxExporterCustomConfig: {}
  #  rules:
  #   - pattern: ".*"

  serviceMonitor:

    # -- Create ServiceMonitor to start scraping metrics. ServiceMonitor CRD needs to be created in advance.
    #
    create: false

    # -- ServiceMonitorSelector of the prometheus instance.
    #
    prometheusLabelSelector: {}
      # release: prometheus

    # -- Scrape interval for the JMX service.
    #
    scrapeIntervalSeconds: 30

  grafana:

    # -- Create ConfigMaps with Grafana dashboards
    #
    createDashboards: false

    # -- Label selector for Grafana dashboard importer sidecar
    #
    dashboardLabels: {}
      # grafana_dashboard: dc_monitoring

    # -- Annotations added to Grafana dashboards ConfigMaps. See: https://github.com/kiwigrid/k8s-sidecar#usage
    #
    dashboardAnnotations: {}
      # k8s-sidecar-target-directory: /tmp/dashboards/example-folder

# Confluence Synchrony configuration
# https://confluence.atlassian.com/doc/configuring-synchrony-858772125.html
synchrony:

  # -- Set to 'true' if Synchrony (i.e. collaborative editing) should be enabled.
  # This will result in a separate StatefulSet and Service to be created for Synchrony.
  # If disabled, then collaborative editing will be disabled in Confluence.
  enabled: true

  # -- Number of Synchrony pods
  #
  replicaCount: 1

  # -- Custom annotations that will be applied to all Synchrony pods.
  # When undefined, default to '.Values.podAnnotations' which are Confluence pod annotations (if defined)
  podAnnotations: {}
  #  name: <value>

  # K8s Synchrony Service configuration
  #
  service:

    # -- The port on which the Synchrony K8s Service will listen
    #
    port: 80

    # -- The type of K8s service to use for Synchrony
    #
    type: ClusterIP

    # -- Use specific loadBalancerIP. Only applies to service type LoadBalancer.
    #
    loadBalancerIP:

    # -- Annotations to apply to Synchrony Service
    #
    annotations: {}

  securityContextEnabled: true

  securityContext:
    fsGroup: 2002
  containerSecurityContext: {}
  setPermissions: true

  # Port definitions
  #
  ports:

    # -- The port on which the Synchrony container listens for HTTP traffic
    #
    http: 8091

    # -- The port on which the Synchrony container listens for Hazelcast traffic
    #
    hazelcast: 5701

  # Confirm that Synchrony is up and running with a ReadinessProbe
  # https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#define-readiness-probes
  #
  readinessProbe:
    healthcheckPath: "/synchrony/heartbeat"
    initialDelaySeconds: 5
    periodSeconds: 1
    failureThreshold: 10

  # Synchrony Pod resource requests
  #
  resources:
    jvm:
      minHeap: "1g"
      maxHeap: "2g"
      stackSize: "2048k"

    container:
      requests:

        cpu: "250m"
        memory: "1G"
 
  additionalJvmArgs: []
    #- -Dsynchrony.example.system.property=46

  shutdown:

  additionalLibraries: []

  additionalVolumeMounts: []

  # -- Defines any additional ports for the Synchrony container.
  #
  additionalPorts: []

  topologySpreadConstraints: []

  additionalCertificates:
    secretName:
    customCmd:

# Fluentd configuration

fluentd:

  # -- Set to 'true' if the Fluentd sidecar (DaemonSet) should be added to each pod
  #
  enabled: false

  # -- The Fluentd sidecar image repository
  #
  imageRepo: fluent/fluentd-kubernetes-daemonset

  # -- The Fluentd sidecar image tag
  #
  imageTag: v1.11.5-debian-elasticsearch7-1.2

  resources: {}

  command:

  customConfigFile: false

  # -- Custom fluent.conf file
  #
  fluentdCustomConfig: {}

  httpPort: 9880

  # Elasticsearch config based on your ELK stack
  #
  elasticsearch:

    # -- Set to 'true' if Fluentd should send all log events to an Elasticsearch service.
    #
    enabled: true

    # -- The hostname of the Elasticsearch service that Fluentd should send logs to.
    #
    hostname: elasticsearch

    # -- The prefix of the Elasticsearch index name that will be used
    #
    indexNamePrefix: confluence

  # -- Specify custom volumes to be added to Fluentd container (e.g. more log sources)
  #
  extraVolumes: []

# -- Custom annotations that will be applied to all Confluence pods
#
podAnnotations: {}
#  name: <value>

# -- Custom labels that will be applied to all Confluence pods
#
podLabels: {}
#  name: <value>

# -- Standard K8s node-selectors that will be applied to all Confluence pods
#
nodeSelector: {}
#  name: <value>

# -- Standard K8s tolerations that will be applied to all Confluence pods
#
tolerations: []
# - effect: <name>
#   operator: <operator>
#   key: <key>

# -- Standard K8s affinities that will be applied to all Confluence pods
#
affinity: {}

schedulerName:

priorityClassName:

# -- Additional container definitions that will be added to all Confluence pods
#
additionalContainers: []

additionalInitContainers: []

additionalLabels: {}

additionalFiles: []

additionalHosts: []

podDisruptionBudget:
  enabled: false
  labels: {}
  annotations: {}
  minAvailable:
  maxUnavailable:

# -- Create additional ConfigMaps with given names, keys and content. Ther Helm release name will be used as a prefix
# for a ConfigMap name, fileName is used as subPath
#
additionalConfigMaps: []

atlassianAnalyticsAndSupport:

  analytics:

    # -- Mount ConfigMap with selected Helm chart values as a JSON
    # which DC products will read and send analytics events to Atlassian data pipelines
    #
    enabled: true

  helmValues:

    # -- Mount ConfigMap with selected Helm chart values as a YAML file
    # which can be optionally including to support.zip
    #
    enabled: true

# -- Metadata and pod spec for pods started in Helm tests
#
testPods:
  resources: {}
  labels: {}
  annotations: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  schedulerName:
  image:
    permissionsTestContainer: debian:stable-slim
    statusTestContainer: alpine:latest

openshift:

  runWithRestrictedSCC: false


opensearch:

  # -- Deploy OpenSearch Helm chart and Configure Confluence to use it as a search platform
  #
  enabled: false

  credentials:
    # -- Let the Helm chart create a secret with an auto generated initial admin password
    #
    createSecret: true

    # -- Use an existing secret with the key OPENSEARCH_INITIAL_ADMIN_PASSWORD holding the initial admin password
    #
    existingSecretRef:
      name:

  # -- OpenSearch helm specific values, see: https://github.com/opensearch-project/helm-charts/blob/main/charts/opensearch/values.yaml
  #
  singleNode: true
  resources:
    requests:
      cpu: 1
      memory: 1Gi
  persistence:
    size: 10Gi
  extraEnvs:
    - name: plugins.security.ssl.http.enabled
      value: "false"
  envFrom:
    - secretRef:
         # -- If using a pre-created secret, make sure to change secret name to match opensearch.credentials.existingSecretRef.name
         #
         name: opensearch-initial-password


